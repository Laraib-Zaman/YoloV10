{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8632884,"sourceType":"datasetVersion","datasetId":5169278},{"sourceId":8632930,"sourceType":"datasetVersion","datasetId":5169316},{"sourceId":8655115,"sourceType":"datasetVersion","datasetId":5184902}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q git+https://github.com/THU-MIG/yolov10.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T13:11:21.283643Z","iopub.execute_input":"2024-06-10T13:11:21.284691Z","iopub.status.idle":"2024-06-10T13:11:57.436505Z","shell.execute_reply.started":"2024-06-10T13:11:21.284644Z","shell.execute_reply":"2024-06-10T13:11:57.435101Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir -p weights\n\n!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10b.pt\n!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10x.pt\n!wget -P weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10l.pt\n!ls -lh weights","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:11:57.439460Z","iopub.execute_input":"2024-06-10T13:11:57.440104Z","iopub.status.idle":"2024-06-10T13:12:10.739540Z","shell.execute_reply.started":"2024-06-10T13:11:57.440046Z","shell.execute_reply":"2024-06-10T13:12:10.737865Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"total 408M\n-rw-r--r-- 1 root root  80M May 23 09:38 yolov10b.pt\n-rw-r--r-- 1 root root 100M May 23 09:38 yolov10l.pt\n-rw-r--r-- 1 root root  64M May 23 09:38 yolov10m.pt\n-rw-r--r-- 1 root root  11M May 23 09:38 yolov10n.pt\n-rw-r--r-- 1 root root  32M May 23 09:38 yolov10s.pt\n-rw-r--r-- 1 root root 123M May 23 09:38 yolov10x.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLOv10\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:12:10.741886Z","iopub.execute_input":"2024-06-10T13:12:10.742347Z","iopub.status.idle":"2024-06-10T13:12:16.953367Z","shell.execute_reply.started":"2024-06-10T13:12:10.742305Z","shell.execute_reply":"2024-06-10T13:12:16.952355Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# another way\n\nmodel = YOLOv10('weights/yolov10b.pt')\n\n\nmodel.train(data='/kaggle/input/config/config_sample.yaml', epochs=100, batch=16, imgsz=416)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:12:20.112769Z","iopub.execute_input":"2024-06-10T13:12:20.113939Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.2.30 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.1.34  Python-3.10.13 torch-2.1.2+cpu CPU (Intel Xeon 2.20GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=weights/yolov10b.pt, data=/kaggle/input/config/config_sample.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/yolov10/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|| 755k/755k [00:00<00:00, 14.5MB/s]\n2024-06-10 13:12:24,252\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-10 13:12:25,433\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-10 13:12:28.447704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-10 13:12:28.447873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-10 13:12:28.608491: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  4   1444864  ultralytics.nn.modules.block.C2f             [256, 256, 4, True]           \n  5                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n  6                  -1  4   5773312  ultralytics.nn.modules.block.C2f             [512, 512, 4, True]           \n  7                  -1  1    268800  ultralytics.nn.modules.block.SCDown          [512, 512, 3, 2]              \n  8                  -1  2   1338368  ultralytics.nn.modules.block.C2fCIB          [512, 512, 2, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  2   1600512  ultralytics.nn.modules.block.C2fCIB          [1024, 512, 2, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  2    919552  ultralytics.nn.modules.block.C2f             [768, 256, 2]                 \n 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  2   1469440  ultralytics.nn.modules.block.C2fCIB          [768, 512, 2, True]           \n 20                  -1  1    268800  ultralytics.nn.modules.block.SCDown          [512, 512, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  2   1600512  ultralytics.nn.modules.block.C2fCIB          [1024, 512, 2, True]          \n 23        [16, 19, 22]  1   2828200  ultralytics.nn.modules.head.v10Detect        [4, [256, 512, 512]]          \nYOLOv10b summary: 518 layers, 20457192 parameters, 20457176 gradients, 98.7 GFLOPs\n\nTransferred 823/835 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240610_131250-4rb3f26t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sadhwani/YOLOv8/runs/4rb3f26t' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/sadhwani/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sadhwani/YOLOv8' target=\"_blank\">https://wandb.ai/sadhwani/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sadhwani/YOLOv8/runs/4rb3f26t' target=\"_blank\">https://wandb.ai/sadhwani/YOLOv8/runs/4rb3f26t</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.23.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/sample-data/sample_ds(CR)/Train/labels... 153 images, 1 backgrounds, 0 corrupt: 100%|| 154/154 [00:00<00:00, 184.74it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 Cache directory /kaggle/input/sample-data/sample_ds(CR)/Train is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/sample-data/sample_ds(CR)/Test/labels... 33 images, 0 backgrounds, 0 corrupt: 100%|| 33/33 [00:00<00:00, 188.75it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 Cache directory /kaggle/input/sample-data/sample_ds(CR)/Test is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 135 weight(decay=0.0), 148 weight(decay=0.0005), 147 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \nImage sizes 416 train, 416 val\nUsing 0 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100         0G       3.33       4.29      1.999      3.069      5.419      1.749         34        416: 100%|| 10/10 [05:09<00:00, 30.91s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:16<00:00,  8.16s/it]","output_type":"stream"},{"name":"stdout","text":"                   all         33         92      0.792      0.115     0.0509     0.0204\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100         0G      2.148      2.452      1.374      2.073      3.566      1.304         71        416:  40%|      | 4/10 [02:01<03:02, 30.48s/it]","output_type":"stream"}]},{"cell_type":"code","source":"# test on unseen dataset \n!yolo task=detect mode=predict conf=0.25 save=True model='/kaggle/working/runs/detect/train/weights/best.pt' source='/kaggle/input/test-ds-1'\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Directory containing the predicted images\npredicted_images_dir = '/kaggle/working/runs/detect/predict3'\n\n# Get list of image files in the directory\npredicted_image_files = [os.path.join(predicted_images_dir, f) for f in os.listdir(predicted_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n\ndef display_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n\n    plt.figure(figsize=(10, 10))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n\n# Display each predicted image\nfor image_file in predicted_image_files:\n    display_image(image_file)\n","metadata":{},"execution_count":null,"outputs":[]}]}